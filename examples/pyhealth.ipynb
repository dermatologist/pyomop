{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc990a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate database and export data\n",
    "!pyomop -e GiBleed -v 5.3 --pyhealth-path ~/pyhealth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbfcb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'person_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_7491/1063179767.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m pyhealth.datasets \u001b[38;5;28;01mimport\u001b[39;00m OMOPDataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = OMOPDataset(\n\u001b[32m      3\u001b[39m         dataset_name=\u001b[33m\"GiBleed\"\u001b[39m,\n\u001b[32m      4\u001b[39m         root=\u001b[33m\"~/pyhealth_bak\"\u001b[39m,\n\u001b[32m      5\u001b[39m         tables=[\u001b[33m\"condition_occurrence\"\u001b[39m, \u001b[33m\"procedure_occurrence\"\u001b[39m, \u001b[33m\"drug_exposure\"\u001b[39m, \u001b[33m\"measurement\"\u001b[39m, \u001b[33m\"person\"\u001b[39m, \u001b[33m\"death\"\u001b[39m,],\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pyhealth/datasets/base_ehr_dataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, root, tables, dataset_name, code_mapping, dev, refresh_cache)\u001b[39m\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pyhealth/datasets/base_ehr_dataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pyhealth/datasets/omop.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, patients)\u001b[39m\n\u001b[32m    113\u001b[39m             sep=\u001b[33m\"\\t\"\u001b[39m,\n\u001b[32m    114\u001b[39m             dtype={\u001b[33m\"person_id\"\u001b[39m: str},\n\u001b[32m    115\u001b[39m         )\n\u001b[32m    116\u001b[39m         \u001b[38;5;66;03m# merge\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         df = pd.merge(person_df, visit_occurrence_df, on=\u001b[33m\"person_id\"\u001b[39m, how=\u001b[33m\"left\"\u001b[39m)\n\u001b[32m    118\u001b[39m         df = pd.merge(df, death_df, on=\u001b[33m\"person_id\"\u001b[39m, how=\u001b[33m\"left\"\u001b[39m)\n\u001b[32m    119\u001b[39m         \u001b[38;5;66;03m# sort by admission time\u001b[39;00m\n\u001b[32m    120\u001b[39m         df = df.sort_values(\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    106\u001b[39m     copy: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    107\u001b[39m     indicator: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    108\u001b[39m     validate: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    109\u001b[39m ) -> DataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     op = _MergeOperation(\n\u001b[32m    111\u001b[39m         left,\n\u001b[32m    112\u001b[39m         right,\n\u001b[32m    113\u001b[39m         how=how,\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    699\u001b[39m         (\n\u001b[32m    700\u001b[39m             self.left_join_keys,\n\u001b[32m    701\u001b[39m             self.right_join_keys,\n\u001b[32m    702\u001b[39m             self.join_names,\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    704\u001b[39m \n\u001b[32m    705\u001b[39m         \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    706\u001b[39m         \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1158\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1159\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1160\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1161\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1163\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1164\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1165\u001b[39m                             right_keys.append(right.index)\n",
      "\u001b[32m~/venv/torch/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1846\u001b[39m                 .get_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   1847\u001b[39m                 ._values\n\u001b[32m   1848\u001b[39m             )\n\u001b[32m   1849\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1850\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1851\u001b[39m \n\u001b[32m   1852\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1853\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'person_id'"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import OMOPDataset\n",
    "dataset = OMOPDataset(\n",
    "        dataset_name=\"GiBleed\",\n",
    "        root=\"~/pyhealth_bak\",\n",
    "        tables=[\"condition_occurrence\", \"procedure_occurrence\", \"drug_exposure\", \"measurement\", \"person\", \"death\",],\n",
    "        dev=True,\n",
    "        refresh_cache=True,\n",
    "    )\n",
    "dataset.stat()\n",
    "dataset.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
